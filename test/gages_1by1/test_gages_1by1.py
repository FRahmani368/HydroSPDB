import os
import unittest
from functools import reduce

import torch

import definitions
from data import GagesConfig, GagesSource
from data.data_input import _basin_norm, GagesModel, save_datamodel
from hydroDL.master.master import master_test_1by1
from utils import serialize_pickle, unserialize_pickle, serialize_numpy, unserialize_numpy
from visual.plot_model import plot_we_need
import numpy as np

from visual.plot_stat import plot_loss_early_stop


class MyTestCase(unittest.TestCase):
    def setUp(self) -> None:
        """before all of these, natural flow model need to be generated by config.ini of gages dataset, and it need
        to be moved to right dir manually """
        config_dir = definitions.CONFIG_DIR
        self.config_file = os.path.join(config_dir, "gages1by1/config_expa.ini")
        self.subdir = r"gages1by1/expa"
        self.config_data = GagesConfig.set_subdir(self.config_file, self.subdir)
        self.flow_pred_file = os.path.join(self.config_data.data_path['Temp'], 'flow_pred')
        self.flow_obs_file = os.path.join(self.config_data.data_path['Temp'], 'flow_obs')

    def test_data_model(self):
        quick_data_dir = os.path.join(self.config_data.data_path["DB"], "quickdata")
        data_dir = os.path.join(quick_data_dir, "conus_85-05_nan-0.1_00-1.0")
        data_model_test = GagesModel.load_datamodel(data_dir,
                                                    data_source_file_name='test_data_source.txt',
                                                    stat_file_name='test_Statistics.json',
                                                    flow_file_name='test_flow.npy',
                                                    forcing_file_name='test_forcing.npy',
                                                    attr_file_name='test_attr.npy',
                                                    f_dict_file_name='test_dictFactorize.json',
                                                    var_dict_file_name='test_dictAttribute.json',
                                                    t_s_dict_file_name='test_dictTimeSpace.json')
        gages_model_test = GagesModel.update_data_model(self.config_data, data_model_test)
        save_datamodel(gages_model_test, data_source_file_name='test_data_source.txt',
                       stat_file_name='test_Statistics.json', flow_file_name='test_flow',
                       forcing_file_name='test_forcing', attr_file_name='test_attr',
                       f_dict_file_name='test_dictFactorize.json', var_dict_file_name='test_dictAttribute.json',
                       t_s_dict_file_name='test_dictTimeSpace.json')
        print("read and save data model")

    def test_compact_data_model(self):
        data_dir_temp = '/'.join(self.config_data.data_path['Temp'].split('/')[:-1])
        data_dir = os.path.join(data_dir_temp, "exp" + str(1))
        data_model = GagesModel.load_datamodel(data_dir,
                                               data_source_file_name='test_data_source.txt',
                                               stat_file_name='test_Statistics.json',
                                               flow_file_name='test_flow.npy',
                                               forcing_file_name='test_forcing.npy',
                                               attr_file_name='test_attr.npy',
                                               f_dict_file_name='test_dictFactorize.json',
                                               var_dict_file_name='test_dictAttribute.json',
                                               t_s_dict_file_name='test_dictTimeSpace.json')
        data_model_lst = []
        for j in range(0, 2):  # data_model_i.data_flow.shape[0]
            data_models_j = GagesModel.which_data_model(data_model, j)
            data_model_lst.append(data_models_j)
        gages_model_test = GagesModel.load_datamodel(self.config_data.data_path["Temp"],
                                                     data_source_file_name='test_data_source.txt',
                                                     stat_file_name='test_Statistics.json',
                                                     flow_file_name='test_flow.npy',
                                                     forcing_file_name='test_forcing.npy',
                                                     attr_file_name='test_attr.npy',
                                                     f_dict_file_name='test_dictFactorize.json',
                                                     var_dict_file_name='test_dictAttribute.json',
                                                     t_s_dict_file_name='test_dictTimeSpace.json')
        data_model_test = GagesModel.compact_data_model(data_model_lst, gages_model_test.data_source)
        print(data_model_test)

    def test_test_gages_iter(self):
        data_config = self.config_data.read_data_config()
        regions = data_config["regions"]
        data_model_test_lst = []
        with torch.cuda.device(1):
            obs_lsts = []
            pred_lsts = []
            for i in range(1, len(regions) + 1):
                data_dir_i_temp = '/'.join(self.config_data.data_path['Temp'].split('/')[:-1])
                data_dir_i = os.path.join(data_dir_i_temp, "exp" + str(i))
                data_model_i = GagesModel.load_datamodel(data_dir_i,
                                                         data_source_file_name='test_data_source.txt',
                                                         stat_file_name='test_Statistics.json',
                                                         flow_file_name='test_flow.npy',
                                                         forcing_file_name='test_forcing.npy',
                                                         attr_file_name='test_attr.npy',
                                                         f_dict_file_name='test_dictFactorize.json',
                                                         var_dict_file_name='test_dictAttribute.json',
                                                         t_s_dict_file_name='test_dictTimeSpace.json')
                data_model_test_lst.append(data_model_i)
                obs_lst = []
                pred_lst = []
                for j in range(0, data_model_i.data_flow.shape[0]):
                    print("\n", "Testing model", str(j + 1), "of", regions[i - 1], "region", ":\n")
                    data_models_j = GagesModel.which_data_model(data_model_i, j)
                    pred, obs = master_test_1by1(data_models_j)
                    basin_area = data_models_j.data_source.read_attr(data_models_j.t_s_dict["sites_id"], ['DRAIN_SQKM'],
                                                                     is_return_dict=False)
                    mean_prep = data_models_j.data_source.read_attr(data_models_j.t_s_dict["sites_id"],
                                                                    ['PPTAVG_BASIN'],
                                                                    is_return_dict=False)
                    mean_prep = mean_prep / 365 * 10
                    pred = _basin_norm(pred, basin_area, mean_prep, to_norm=False)
                    obs = _basin_norm(obs, basin_area, mean_prep, to_norm=False)
                    obs_lst.append(obs.flatten())
                    pred_lst.append(pred.flatten())
                preds = np.array(pred_lst)
                obss = np.array(obs_lst)
                obs_lsts.append(obss)
                pred_lsts.append(preds)

            obs_final = reduce(lambda a, b: np.vstack((a, b)), obs_lsts)
            pred_final = reduce(lambda a, b: np.vstack((a, b)), pred_lsts)

            serialize_numpy(pred_final, self.flow_pred_file)
            serialize_numpy(obs_final, self.flow_obs_file)

    def test_plot_1by1(self):
        data_config = self.config_data.read_data_config()
        regions = data_config["regions"]
        data_model_test_lst = []
        obs_lsts = []
        pred_lsts = []
        for i in range(1, len(regions) + 1):
            data_dir_i_temp = '/'.join(self.config_data.data_path['Temp'].split('/')[:-1])
            data_dir_i = os.path.join(data_dir_i_temp, "exp" + str(i))
            data_model_i = GagesModel.load_datamodel(data_dir_i,
                                                     data_source_file_name='test_data_source.txt',
                                                     stat_file_name='test_Statistics.json',
                                                     flow_file_name='test_flow.npy',
                                                     forcing_file_name='test_forcing.npy',
                                                     attr_file_name='test_attr.npy',
                                                     f_dict_file_name='test_dictFactorize.json',
                                                     var_dict_file_name='test_dictAttribute.json',
                                                     t_s_dict_file_name='test_dictTimeSpace.json')
            data_model_test_lst.append(data_model_i)

            flow_pred_file_i = os.path.join(data_dir_i, 'flow_pred')
            flow_obs_file_i = os.path.join(data_dir_i, 'flow_obs')
            preds = unserialize_numpy(flow_pred_file_i)
            obss = unserialize_numpy(flow_obs_file_i)
            obs_lsts.append(obss)
            pred_lsts.append(preds)

        # pred_final = unserialize_numpy(self.flow_pred_file)
        # obs_final = unserialize_numpy(self.flow_obs_file)
        obs_final = reduce(lambda a, b: np.vstack((a, b)), obs_lsts)
        pred_final = reduce(lambda a, b: np.vstack((a, b)), pred_lsts)
        gages_model_test = GagesModel.load_datamodel(self.config_data.data_path["Temp"],
                                                     data_source_file_name='test_data_source.txt',
                                                     stat_file_name='test_Statistics.json',
                                                     flow_file_name='test_flow.npy',
                                                     forcing_file_name='test_forcing.npy',
                                                     attr_file_name='test_attr.npy',
                                                     f_dict_file_name='test_dictFactorize.json',
                                                     var_dict_file_name='test_dictAttribute.json',
                                                     t_s_dict_file_name='test_dictTimeSpace.json')

        data_model_test = GagesModel.compact_data_model(data_model_test_lst, gages_model_test.data_source)
        plot_we_need(data_model_test, obs_final, pred_final, id_col="STAID", lon_col="LNG_GAGE", lat_col="LAT_GAGE")


if __name__ == '__main__':
    unittest.main()

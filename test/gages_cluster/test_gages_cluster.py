import unittest

import definitions
from data import GagesConfig, GagesSource, DataModel
from data.data_input import save_datamodel, GagesModel
from data.gages_input_dataset import GagesExploreDataModel
from explore.stat import statError
from hydroDL.master.master import master_train, master_test
import numpy as np
import os
import pandas as pd
from utils.dataset_format import subset_of_dict
from visual import plot_ts_obs_pred
from visual.plot_model import plot_ind_map
import seaborn as sns
import matplotlib.pyplot as plt

from visual.plot_stat import plot_diff_boxes


class MyTestCase(unittest.TestCase):
    """historical data assimilation"""

    def setUp(self) -> None:
        """before all of these, natural flow model need to be generated by config.ini of gages dataset, and it need
        to be moved to right dir manually """
        config_dir = definitions.CONFIG_DIR
        # self.config_file = os.path.join(config_dir, "cluster/config_explore_exp1.ini")
        # self.subdir = r"explore/exp1"
        # self.config_file = os.path.join(config_dir, "cluster/config_explore_exp2.ini")
        # self.subdir = r"explore/exp2"
        self.num_cluster = 2

        self.config_file = os.path.join(config_dir, "cluster/config_explore_exp3.ini")
        self.subdir = r"cluster/exp3"
        self.config_data = GagesConfig.set_subdir(self.config_file, self.subdir)

    def test_plot_basin_area(self):
        # plot a histogram of basin area of all chosen basins
        quick_data_dir = os.path.join(self.config_data.data_path["DB"], "quickdata")
        data_dir = os.path.join(quick_data_dir, "conus_85-05_nan-0.1_00-1.0")
        data_model_train = GagesModel.load_datamodel(data_dir,
                                                     data_source_file_name='data_source.txt',
                                                     stat_file_name='Statistics.json', flow_file_name='flow.npy',
                                                     forcing_file_name='forcing.npy', attr_file_name='attr.npy',
                                                     f_dict_file_name='dictFactorize.json',
                                                     var_dict_file_name='dictAttribute.json',
                                                     t_s_dict_file_name='dictTimeSpace.json')
        usgs_id = data_model_train.t_s_dict["sites_id"]
        attr_lst = ['DRAIN_SQKM']
        data_attr, var_dict, f_dict = data_model_train.data_source.read_attr(usgs_id, attr_lst)
        data_show = data_attr.flatten()
        print("number of small basins: ", data_show[data_show < 1000].size)
        # sns.distplot(data_show, bins=20, kde=False, rug=False)
        # sns.distplot(data_show, bins=100, kde=False, rug=False)
        # plt.xticks(np.arange(0, 50000, 1000))
        # plt.show()

    def test_data_temp_explore(self):
        config_data_1 = self.config_data
        source_data_1 = GagesSource(config_data_1, config_data_1.model_dict["data"]["tRangeTrain"])
        df1 = DataModel(source_data_1)
        save_datamodel(df1, data_source_file_name='data_source.txt',
                       stat_file_name='Statistics.json', flow_file_name='flow', forcing_file_name='forcing',
                       attr_file_name='attr', f_dict_file_name='dictFactorize.json',
                       var_dict_file_name='dictAttribute.json', t_s_dict_file_name='dictTimeSpace.json')

    def test_explore_train_datamodel(self):
        df = GagesModel.load_datamodel(self.config_data.data_path["Temp"], data_source_file_name='data_source.txt',
                                       stat_file_name='Statistics.json', flow_file_name='flow.npy',
                                       forcing_file_name='forcing.npy', attr_file_name='attr.npy',
                                       f_dict_file_name='dictFactorize.json',
                                       var_dict_file_name='dictAttribute.json',
                                       t_s_dict_file_name='dictTimeSpace.json')
        data_input = GagesExploreDataModel(df)
        data_models = data_input.cluster_datamodel(num_cluster=self.num_cluster)
        count = 0
        for data_model in data_models:
            print("saving model", str(count + 1), "\n")
            save_datamodel(data_model, data_source_file_name='data_source.txt',
                           stat_file_name='Statistics.json', flow_file_name='flow', forcing_file_name='forcing',
                           attr_file_name='attr', f_dict_file_name='dictFactorize.json',
                           var_dict_file_name='dictAttribute.json', t_s_dict_file_name='dictTimeSpace.json')
            count += 1

    def test_explore_train(self):
        models_num = 0
        dirs = os.listdir(self.config_data.data_path["Temp"])
        for dir_temp in dirs:
            if os.path.isdir(os.path.join(self.config_data.data_path["Temp"], dir_temp)):
                models_num += 1
        for count in range(models_num):
            print("\n", "training model", str(count + 1), ":\n")
            data_model = GagesModel.load_datamodel(self.config_data.data_path["Temp"], str(count),
                                                   data_source_file_name='data_source.txt',
                                                   stat_file_name='Statistics.json', flow_file_name='flow.npy',
                                                   forcing_file_name='forcing.npy', attr_file_name='attr.npy',
                                                   f_dict_file_name='dictFactorize.json',
                                                   var_dict_file_name='dictAttribute.json',
                                                   t_s_dict_file_name='dictTimeSpace.json')
            # temporary treatment for
            ngrid = data_model.data_attr.shape[0]
            nt = data_model.data_flow.shape[1]
            mini_batch = data_model.data_source.data_config.model_dict['train']['miniBatch']
            if 1 - mini_batch[0] * mini_batch[1] / ngrid / nt < 0:
                print("don't train this one")
            else:
                master_train(data_model)

    def test_data_temp_test_explore(self):
        config_data_test = self.config_data
        source_data_test = GagesSource(config_data_test, config_data_test.model_dict["data"]["tRangeTest"])
        df_test = DataModel(source_data_test)
        save_datamodel(df_test, data_source_file_name='test_data_source.txt',
                       stat_file_name='test_Statistics.json', flow_file_name='test_flow',
                       forcing_file_name='test_forcing', attr_file_name='test_attr',
                       f_dict_file_name='test_dictFactorize.json', var_dict_file_name='test_dictAttribute.json',
                       t_s_dict_file_name='test_dictTimeSpace.json')

    def test_explore_test_datamodel(self):
        df_test = GagesModel.load_datamodel(self.config_data.data_path["Temp"],
                                            data_source_file_name='test_data_source.txt',
                                            stat_file_name='test_Statistics.json', flow_file_name='test_flow.npy',
                                            forcing_file_name='test_forcing.npy', attr_file_name='test_attr.npy',
                                            f_dict_file_name='test_dictFactorize.json',
                                            var_dict_file_name='test_dictAttribute.json',
                                            t_s_dict_file_name='test_dictTimeSpace.json')
        data_input_test = GagesExploreDataModel(df_test)

        models_num = 0
        dirs = os.listdir(self.config_data.data_path["Temp"])
        for dir_temp in dirs:
            if os.path.isdir(os.path.join(self.config_data.data_path["Temp"], dir_temp)):
                models_num += 1
        for count in range(models_num):
            print("saving test model", str(count + 1), ":\n")
            data_train_model = GagesModel.load_datamodel(self.config_data.data_path["Temp"], str(count),
                                                         data_source_file_name='data_source.txt',
                                                         stat_file_name='Statistics.json', flow_file_name='flow.npy',
                                                         forcing_file_name='forcing.npy', attr_file_name='attr.npy',
                                                         f_dict_file_name='dictFactorize.json',
                                                         var_dict_file_name='dictAttribute.json',
                                                         t_s_dict_file_name='dictTimeSpace.json')
            sites_id_i = data_train_model.t_s_dict["sites_id"]
            data_test_model = data_input_test.choose_datamodel_nodam(sites_id_i, count)
            save_datamodel(data_test_model, data_source_file_name='test_data_source.txt',
                           stat_file_name='test_Statistics.json', flow_file_name='test_flow',
                           forcing_file_name='test_forcing', attr_file_name='test_attr',
                           f_dict_file_name='test_dictFactorize.json', var_dict_file_name='test_dictAttribute.json',
                           t_s_dict_file_name='test_dictTimeSpace.json')

    def test_explore_test(self):
        models_num = 0
        dirs = os.listdir(self.config_data.data_path["Temp"])
        for dir_temp in dirs:
            if os.path.isdir(os.path.join(self.config_data.data_path["Temp"], dir_temp)):
                models_num += 1
        for count in range(models_num):
            print("\n", "testing model", str(count + 1), ":\n")
            data_model = GagesModel.load_datamodel(self.config_data.data_path["Temp"], str(count),
                                                   data_source_file_name='test_data_source.txt',
                                                   stat_file_name='test_Statistics.json',
                                                   flow_file_name='test_flow.npy',
                                                   forcing_file_name='test_forcing.npy', attr_file_name='test_attr.npy',
                                                   f_dict_file_name='test_dictFactorize.json',
                                                   var_dict_file_name='test_dictAttribute.json',
                                                   t_s_dict_file_name='test_dictTimeSpace.json')
            pred, obs = master_test(data_model)
            pred = pred.reshape(pred.shape[0], pred.shape[1])
            obs = obs.reshape(obs.shape[0], obs.shape[1])
            inds = statError(obs, pred)
            show_me_num = 5
            t_s_dict = data_model.t_s_dict
            sites = np.array(t_s_dict["sites_id"])
            t_range = np.array(t_s_dict["t_final_range"])
            ts_fig = plot_ts_obs_pred(obs, pred, sites, t_range, show_me_num)
            ts_fig.savefig(os.path.join(data_model.data_source.data_config.data_path["Out"], "ts_fig.png"))
            # # plot box，使用seaborn库
            keys = ["Bias", "RMSE", "NSE"]
            inds_test = subset_of_dict(inds, keys)
            box_fig = plot_diff_boxes(inds_test)
            box_fig.savefig(os.path.join(data_model.data_source.data_config.data_path["Out"], "box_fig.png"))
            # plot map
            sites_df = pd.DataFrame({"sites": sites, keys[2]: inds_test[keys[2]]})
            plot_ind_map(data_model.data_source.all_configs['gage_point_file'], sites_df)


if __name__ == '__main__':
    unittest.main()

import unittest

import torch

import definitions
from data import GagesConfig, GagesSource, DataModel
from data.data_config import add_model_param
from data.data_input import save_datamodel, GagesModel
from data.gages_input_dataset import GagesDaDataModel
from explore.stat import statError
from hydroDL.master.master import train_lstm_da, test_lstm_da
import numpy as np
import os
import pandas as pd
from utils.dataset_format import subset_of_dict
from visual import plot_ts_obs_pred
from visual.plot_model import plot_boxes_inds, plot_ind_map


class MyTestCase(unittest.TestCase):
    """historical data assimilation"""

    def setUp(self) -> None:
        """before all of these, natural flow model need to be generated by config.ini of gages dataset, and it need
        to be moved to right dir manually """
        config_dir = definitions.CONFIG_DIR
        # self.config_file = os.path.join(config_dir, "da/config_da_exp1.ini")
        # self.subdir = r"da/exp1"
        # self.config_file = os.path.join(config_dir, "da/config_da_exp2.ini")
        # self.subdir = r"da/exp2"
        self.config_file = os.path.join(config_dir, "da/config_exp10.ini")
        self.subdir = r"da/exp10"
        self.config_data = GagesConfig.set_subdir(self.config_file, self.subdir)
        add_model_param(self.config_data, "model", seqLength=7)
        # choose some small basins, unit: SQKM
        self.basin_area_screen = 100

    def test_da_data_temp(self):
        quick_data_dir = os.path.join(self.config_data.data_path["DB"], "quickdata")
        data_dir = os.path.join(quick_data_dir, "allnonref_85-05_nan-0.1_00-1.0")
        data_model_train = GagesModel.load_datamodel(data_dir,
                                                     data_source_file_name='data_source.txt',
                                                     stat_file_name='Statistics.json', flow_file_name='flow.npy',
                                                     forcing_file_name='forcing.npy', attr_file_name='attr.npy',
                                                     f_dict_file_name='dictFactorize.json',
                                                     var_dict_file_name='dictAttribute.json',
                                                     t_s_dict_file_name='dictTimeSpace.json')
        data_model_test = GagesModel.load_datamodel(data_dir,
                                                    data_source_file_name='test_data_source.txt',
                                                    stat_file_name='test_Statistics.json',
                                                    flow_file_name='test_flow.npy',
                                                    forcing_file_name='test_forcing.npy',
                                                    attr_file_name='test_attr.npy',
                                                    f_dict_file_name='test_dictFactorize.json',
                                                    var_dict_file_name='test_dictAttribute.json',
                                                    t_s_dict_file_name='test_dictTimeSpace.json')
        gages_model_train = GagesModel.update_data_model(self.config_data, data_model_train)
        gages_model_test = GagesModel.update_data_model(self.config_data, data_model_test)
        save_datamodel(gages_model_train, data_source_file_name='data_source.txt',
                       stat_file_name='Statistics.json', flow_file_name='flow', forcing_file_name='forcing',
                       attr_file_name='attr', f_dict_file_name='dictFactorize.json',
                       var_dict_file_name='dictAttribute.json', t_s_dict_file_name='dictTimeSpace.json')
        save_datamodel(gages_model_test, data_source_file_name='test_data_source.txt',
                       stat_file_name='test_Statistics.json', flow_file_name='test_flow',
                       forcing_file_name='test_forcing', attr_file_name='test_attr',
                       f_dict_file_name='test_dictFactorize.json', var_dict_file_name='test_dictAttribute.json',
                       t_s_dict_file_name='test_dictTimeSpace.json')
        print("read and save data model")

    def test_da_train(self):
        with torch.cuda.device(2):
            df = GagesModel.load_datamodel(self.config_data.data_path["Temp"], data_source_file_name='data_source.txt',
                                           stat_file_name='Statistics.json', flow_file_name='flow.npy',
                                           forcing_file_name='forcing.npy', attr_file_name='attr.npy',
                                           f_dict_file_name='dictFactorize.json',
                                           var_dict_file_name='dictAttribute.json',
                                           t_s_dict_file_name='dictTimeSpace.json')
            data_model = GagesDaDataModel(df)
            pre_trained_model_epoch = 70
            train_lstm_da(data_model, pre_trained_model_epoch=pre_trained_model_epoch)

    def test_da_test(self):
        with torch.cuda.device(2):
            df1 = GagesModel.load_datamodel(self.config_data.data_path["Temp"],
                                            data_source_file_name='test_data_source.txt',
                                            stat_file_name='test_Statistics.json', flow_file_name='test_flow.npy',
                                            forcing_file_name='test_forcing.npy', attr_file_name='test_attr.npy',
                                            f_dict_file_name='test_dictFactorize.json',
                                            var_dict_file_name='test_dictAttribute.json',
                                            t_s_dict_file_name='test_dictTimeSpace.json')

            data_model = GagesDaDataModel(df1)
            pred, obs = test_lstm_da(data_model)

            pred = pred.reshape(pred.shape[0], pred.shape[1])
            obs = obs.reshape(obs.shape[0], obs.shape[1])

            inds = statError(obs, pred)
            show_me_num = 5
            t_s_dict = data_model.data_model.t_s_dict
            sites = np.array(t_s_dict["sites_id"])
            t_range = np.array(t_s_dict["t_final_range"])
            time_seq_length = data_model.data_model.data_source.data_config.model_dict['model']['seqLength']
            time_start = np.datetime64(t_range[0]) + np.timedelta64(time_seq_length, 'D')
            t_range[0] = np.datetime_as_string(time_start, unit='D')
            ts_fig = plot_ts_obs_pred(obs, pred, sites, t_range, show_me_num)
            ts_fig.savefig(os.path.join(self.config_data.data_path["Out"], "ts_fig.png"))
            # # plot box，使用seaborn库
            keys = ["Bias", "RMSE", "NSE"]
            inds_test = subset_of_dict(inds, keys)
            box_fig = plot_boxes_inds(inds_test)
            box_fig.savefig(os.path.join(self.config_data.data_path["Out"], "box_fig.png"))
            # plot map
            sites_df = pd.DataFrame({"sites": sites, keys[2]: inds_test[keys[2]]})
            plot_ind_map(df1.data_source.all_configs['gage_point_file'], sites_df)


if __name__ == '__main__':
    unittest.main()

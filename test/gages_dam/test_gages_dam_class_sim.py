import unittest

import torch

import definitions
from data import GagesConfig, GagesSource, DataModel
from data.data_config import add_model_param
from data.data_input import save_datamodel, GagesModel, _basin_norm, save_result
from data.gages_input_dataset import GagesDamDataModel, GagesModels, GagesSimDataModel, choose_which_purpose
from data.nid_input import NidModel, save_nidinput
from explore.stat import statError
from hydroDL.master.master import master_train, master_test, master_train_natural_flow, master_test_natural_flow
import numpy as np
import os
import pandas as pd

from utils import serialize_json, unserialize_json
from utils.dataset_format import subset_of_dict
from visual import plot_ts_obs_pred
from visual.plot_model import plot_boxes_inds, plot_ind_map, plot_we_need


class MyTestCase(unittest.TestCase):
    """historical data assimilation"""

    def setUp(self) -> None:
        """before all of these, natural flow model need to be generated by config.ini of gages dataset, and it need
        to be moved to right dir manually """
        config_dir = definitions.CONFIG_DIR
        self.sim_config_file = os.path.join(config_dir, "dam/config1_exp8.ini")
        self.config_file = os.path.join(config_dir, "dam/config2_exp8.ini")
        self.subdir = "dam/exp8"
        self.config_data = GagesConfig.set_subdir(self.config_file, self.subdir)
        self.sim_config_data = GagesConfig.set_subdir(self.sim_config_file, self.subdir)
        add_model_param(self.config_data, "model", seqLength=1)
        # self.nid_file = 'PA_U.xlsx'
        # self.nid_file = 'OH_U.xlsx'
        self.nid_file = 'NID2018_U.xlsx'
        self.test_epoch = 300

    def test_dam_train(self):
        quick_data_dir = os.path.join(self.config_data.data_path["DB"], "quickdata")
        sim_data_dir = os.path.join(quick_data_dir, "allref_85-05_nan-0.1_00-1.0")
        data_dir = os.path.join(quick_data_dir, "allnonref_85-05_nan-0.1_00-1.0")
        data_model_sim8595 = GagesModel.load_datamodel(sim_data_dir,
                                                       data_source_file_name='data_source.txt',
                                                       stat_file_name='Statistics.json', flow_file_name='flow.npy',
                                                       forcing_file_name='forcing.npy', attr_file_name='attr.npy',
                                                       f_dict_file_name='dictFactorize.json',
                                                       var_dict_file_name='dictAttribute.json',
                                                       t_s_dict_file_name='dictTimeSpace.json')
        data_model_8595 = GagesModel.load_datamodel(data_dir,
                                                    data_source_file_name='data_source.txt',
                                                    stat_file_name='Statistics.json', flow_file_name='flow.npy',
                                                    forcing_file_name='forcing.npy', attr_file_name='attr.npy',
                                                    f_dict_file_name='dictFactorize.json',
                                                    var_dict_file_name='dictAttribute.json',
                                                    t_s_dict_file_name='dictTimeSpace.json')
        sim_gages_model_train = GagesModel.update_data_model(self.sim_config_data, data_model_sim8595,
                                                             data_attr_update=True)
        gages_model_train = GagesModel.update_data_model(self.config_data, data_model_8595, data_attr_update=True)
        nid_dir = os.path.join("/".join(self.config_data.data_path["DB"].split("/")[:-1]), "nid", "quickdata")
        gage_main_dam_purpose = unserialize_json(os.path.join(nid_dir, "dam_main_purpose_dict.json"))
        gage_main_dam_purpose_lst = list(gage_main_dam_purpose.values())
        gage_main_dam_purpose_unique = np.unique(gage_main_dam_purpose_lst)
        nid_dir = os.path.join("/".join(self.config_data.data_path["DB"].split("/")[:-1]), "nid", "quickdata")
        nid_input = NidModel.load_nidmodel(nid_dir, nid_file=self.nid_file,
                                           nid_source_file_name='nid_source.txt',
                                           nid_data_file_name='nid_data.shp')
        gage_main_dam_purpose = unserialize_json(os.path.join(nid_dir, "dam_main_purpose_dict.json"))
        data_input = GagesDamDataModel(gages_model_train, nid_input, True, gage_main_dam_purpose)
        with torch.cuda.device(0):
            for i in range(0, gage_main_dam_purpose_unique.size):
                sim_gages_model_train.update_model_param('train', nEpoch=300)
                gages_input = choose_which_purpose(data_input, purpose=gage_main_dam_purpose_unique[i])
                new_temp_dir = os.path.join(gages_input.data_source.data_config.model_dict["dir"]["Temp"],
                                            gage_main_dam_purpose_unique[i])
                new_out_dir = os.path.join(gages_input.data_source.data_config.model_dict["dir"]["Out"],
                                           gage_main_dam_purpose_unique[i])
                gages_input.update_datamodel_dir(new_temp_dir, new_out_dir)
                data_model = GagesSimDataModel(sim_gages_model_train, gages_input)
                # pre_trained_model_epoch = 25
                # master_train_natural_flow(data_model, pre_trained_model_epoch=pre_trained_model_epoch)
                master_train_natural_flow(data_model)

    def test_dam_test(self):
        quick_data_dir = os.path.join(self.config_data.data_path["DB"], "quickdata")
        sim_data_dir = os.path.join(quick_data_dir, "allref_85-05_nan-0.1_00-1.0")
        data_dir = os.path.join(quick_data_dir, "allnonref_85-05_nan-0.1_00-1.0")
        data_model_sim8595 = GagesModel.load_datamodel(sim_data_dir,
                                                       data_source_file_name='data_source.txt',
                                                       stat_file_name='Statistics.json', flow_file_name='flow.npy',
                                                       forcing_file_name='forcing.npy', attr_file_name='attr.npy',
                                                       f_dict_file_name='dictFactorize.json',
                                                       var_dict_file_name='dictAttribute.json',
                                                       t_s_dict_file_name='dictTimeSpace.json')
        data_model_8595 = GagesModel.load_datamodel(data_dir,
                                                    data_source_file_name='data_source.txt',
                                                    stat_file_name='Statistics.json', flow_file_name='flow.npy',
                                                    forcing_file_name='forcing.npy', attr_file_name='attr.npy',
                                                    f_dict_file_name='dictFactorize.json',
                                                    var_dict_file_name='dictAttribute.json',
                                                    t_s_dict_file_name='dictTimeSpace.json')
        data_model_sim9505 = GagesModel.load_datamodel(sim_data_dir,
                                                       data_source_file_name='test_data_source.txt',
                                                       stat_file_name='test_Statistics.json',
                                                       flow_file_name='test_flow.npy',
                                                       forcing_file_name='test_forcing.npy',
                                                       attr_file_name='test_attr.npy',
                                                       f_dict_file_name='test_dictFactorize.json',
                                                       var_dict_file_name='test_dictAttribute.json',
                                                       t_s_dict_file_name='test_dictTimeSpace.json')
        data_model_9505 = GagesModel.load_datamodel(data_dir,
                                                    data_source_file_name='test_data_source.txt',
                                                    stat_file_name='test_Statistics.json',
                                                    flow_file_name='test_flow.npy',
                                                    forcing_file_name='test_forcing.npy',
                                                    attr_file_name='test_attr.npy',
                                                    f_dict_file_name='test_dictFactorize.json',
                                                    var_dict_file_name='test_dictAttribute.json',
                                                    t_s_dict_file_name='test_dictTimeSpace.json')

        sim_gages_model_train = GagesModel.update_data_model(self.sim_config_data, data_model_sim8595,
                                                             data_attr_update=True)
        gages_model_train = GagesModel.update_data_model(self.config_data, data_model_8595, data_attr_update=True)
        sim_gages_model_test = GagesModel.update_data_model(self.sim_config_data, data_model_sim9505,
                                                            data_attr_update=True,
                                                            train_stat_dict=sim_gages_model_train.stat_dict)
        gages_model_test = GagesModel.update_data_model(self.config_data, data_model_9505, data_attr_update=True,
                                                        train_stat_dict=gages_model_train.stat_dict)
        nid_dir = os.path.join("/".join(self.config_data.data_path["DB"].split("/")[:-1]), "nid", "quickdata")
        nid_input = NidModel.load_nidmodel(nid_dir, nid_file=self.nid_file,
                                           nid_source_file_name='nid_source.txt', nid_data_file_name='nid_data.shp')
        gage_main_dam_purpose = unserialize_json(os.path.join(nid_dir, "dam_main_purpose_dict.json"))
        gage_main_dam_purpose_lst = list(gage_main_dam_purpose.values())
        gage_main_dam_purpose_unique = np.unique(gage_main_dam_purpose_lst)
        data_input = GagesDamDataModel(gages_model_test, nid_input, True, gage_main_dam_purpose)
        for i in range(0, gage_main_dam_purpose_unique.size):
            sim_gages_model_test.update_model_param('train', nEpoch=300)
            gages_input = choose_which_purpose(data_input, purpose=gage_main_dam_purpose_unique[i])
            new_temp_dir = os.path.join(gages_input.data_source.data_config.model_dict["dir"]["Temp"],
                                        gage_main_dam_purpose_unique[i])
            new_out_dir = os.path.join(gages_input.data_source.data_config.model_dict["dir"]["Out"],
                                       gage_main_dam_purpose_unique[i])
            gages_input.update_datamodel_dir(new_temp_dir, new_out_dir)
            model_input = GagesSimDataModel(sim_gages_model_test, gages_input)
            pred, obs = master_test_natural_flow(model_input, epoch=self.test_epoch)
            basin_area = model_input.data_model2.data_source.read_attr(model_input.data_model2.t_s_dict["sites_id"],
                                                                       ['DRAIN_SQKM'], is_return_dict=False)
            mean_prep = model_input.data_model2.data_source.read_attr(model_input.data_model2.t_s_dict["sites_id"],
                                                                      ['PPTAVG_BASIN'], is_return_dict=False)
            mean_prep = mean_prep / 365 * 10
            pred = _basin_norm(pred, basin_area, mean_prep, to_norm=False)
            obs = _basin_norm(obs, basin_area, mean_prep, to_norm=False)
            save_result(model_input.data_model2.data_source.data_config.data_path['Temp'], str(self.test_epoch), pred,
                        obs)
            plot_we_need(gages_input, obs, pred, id_col="STAID", lon_col="LNG_GAGE", lat_col="LAT_GAGE")


if __name__ == '__main__':
    unittest.main()

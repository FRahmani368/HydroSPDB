import unittest

import torch

import definitions
from data import GagesConfig, GagesSource, DataModel
from data.data_config import add_model_param
from data.data_input import save_datamodel, GagesModel
from data.gages_input_dataset import GagesDamDataModel, GagesModels, GagesSimDataModel, GagesInvDataModel
from data.nid_input import NidModel, save_nidinput
from explore.stat import statError
from hydroDL.master.master import master_train, master_test, master_train_natural_flow, train_lstm_inv
import numpy as np
import os
import pandas as pd

from utils import serialize_json, unserialize_json
from utils.dataset_format import subset_of_dict
from visual import plot_ts_obs_pred
from visual.plot_model import plot_boxes_inds, plot_ind_map


class MyTestCase(unittest.TestCase):
    """historical data assimilation"""

    def setUp(self) -> None:
        """before all of these, natural flow model need to be generated by config.ini of gages dataset, and it need
        to be moved to right dir manually """
        config_dir = definitions.CONFIG_DIR
        self.config_file_1 = os.path.join(config_dir, "dam/config1_exp15.ini")
        self.config_file_2 = os.path.join(config_dir, "dam/config2_exp15.ini")
        self.subdir = r"dam/exp15"
        self.config_data_1 = GagesConfig.set_subdir(self.config_file_1, self.subdir)
        self.config_data_2 = GagesConfig.set_subdir(self.config_file_2, self.subdir)
        add_model_param(self.config_data_1, "model", seqLength=1)

        # self.nid_file = 'PA_U.xlsx'
        # self.nid_file = 'OH_U.xlsx'
        self.nid_file = 'NID2018_U.xlsx'

    def test_data_temp_dam(self):
        quick_data_dir = os.path.join(self.config_data_1.data_path["DB"], "quickdata")
        data_dir = os.path.join(quick_data_dir, "allnonref_85-05_nan-0.1_00-1.0")
        # for inv model, datamodel of  train and test are same
        data_model_8595 = GagesModel.load_datamodel(data_dir,
                                                    data_source_file_name='data_source.txt',
                                                    stat_file_name='Statistics.json', flow_file_name='flow.npy',
                                                    forcing_file_name='forcing.npy', attr_file_name='attr.npy',
                                                    f_dict_file_name='dictFactorize.json',
                                                    var_dict_file_name='dictAttribute.json',
                                                    t_s_dict_file_name='dictTimeSpace.json')
        # for 2nd model, datamodel of train and test belong to parts of the test time
        data_model_9505 = GagesModel.load_datamodel(data_dir,
                                                    data_source_file_name='test_data_source.txt',
                                                    stat_file_name='test_Statistics.json',
                                                    flow_file_name='test_flow.npy',
                                                    forcing_file_name='test_forcing.npy',
                                                    attr_file_name='test_attr.npy',
                                                    f_dict_file_name='test_dictFactorize.json',
                                                    var_dict_file_name='test_dictAttribute.json',
                                                    t_s_dict_file_name='test_dictTimeSpace.json')

        t_range1_train = self.config_data_1.model_dict["data"]["tRangeTrain"]
        t_range1_test = self.config_data_1.model_dict["data"]["tRangeTest"]
        gages_model1_train = GagesModel.update_data_model(self.config_data_1, data_model_8595,
                                                          t_range_update=t_range1_train, data_attr_update=True)
        # Because we know data of period "90-95", so that we can get its statistics according to this period
        gages_model1_test = GagesModel.update_data_model(self.config_data_1, data_model_8595,
                                                         t_range_update=t_range1_test, data_attr_update=True)
        t_range2_train = self.config_data_2.model_dict["data"]["tRangeTrain"]
        t_range2_test = self.config_data_2.model_dict["data"]["tRangeTest"]
        gages_model2_train = GagesModel.update_data_model(self.config_data_2, data_model_8595,
                                                          t_range_update=t_range2_train, data_attr_update=True)
        gages_model2_test = GagesModel.update_data_model(self.config_data_2, data_model_9505,
                                                         t_range_update=t_range2_test, data_attr_update=True,
                                                         train_stat_dict=gages_model2_train.stat_dict)
        save_datamodel(gages_model1_train, "1", data_source_file_name='data_source.txt',
                       stat_file_name='Statistics.json', flow_file_name='flow', forcing_file_name='forcing',
                       attr_file_name='attr', f_dict_file_name='dictFactorize.json',
                       var_dict_file_name='dictAttribute.json', t_s_dict_file_name='dictTimeSpace.json')
        save_datamodel(gages_model1_test, "1", data_source_file_name='test_data_source.txt',
                       stat_file_name='test_Statistics.json', flow_file_name='test_flow',
                       forcing_file_name='test_forcing', attr_file_name='test_attr',
                       f_dict_file_name='test_dictFactorize.json', var_dict_file_name='test_dictAttribute.json',
                       t_s_dict_file_name='test_dictTimeSpace.json')
        save_datamodel(gages_model2_train, "2", data_source_file_name='data_source.txt',
                       stat_file_name='Statistics.json', flow_file_name='flow', forcing_file_name='forcing',
                       attr_file_name='attr', f_dict_file_name='dictFactorize.json',
                       var_dict_file_name='dictAttribute.json', t_s_dict_file_name='dictTimeSpace.json')
        save_datamodel(gages_model2_test, "2", data_source_file_name='test_data_source.txt',
                       stat_file_name='test_Statistics.json', flow_file_name='test_flow',
                       forcing_file_name='test_forcing', attr_file_name='test_attr',
                       f_dict_file_name='test_dictFactorize.json', var_dict_file_name='test_dictAttribute.json',
                       t_s_dict_file_name='test_dictTimeSpace.json')
        print("read and save data model")

    def test_dam_train(self):
        with torch.cuda.device(1):
            df1 = GagesModel.load_datamodel(self.config_data_1.data_path["Temp"], "1",
                                            data_source_file_name='data_source.txt',
                                            stat_file_name='Statistics.json', flow_file_name='flow.npy',
                                            forcing_file_name='forcing.npy', attr_file_name='attr.npy',
                                            f_dict_file_name='dictFactorize.json',
                                            var_dict_file_name='dictAttribute.json',
                                            t_s_dict_file_name='dictTimeSpace.json')
            df2 = GagesModel.load_datamodel(self.config_data_2.data_path["Temp"], "2",
                                            data_source_file_name='data_source.txt',
                                            stat_file_name='Statistics.json', flow_file_name='flow.npy',
                                            forcing_file_name='forcing.npy', attr_file_name='attr.npy',
                                            f_dict_file_name='dictFactorize.json',
                                            var_dict_file_name='dictAttribute.json',
                                            t_s_dict_file_name='dictTimeSpace.json')

            nid_dir = os.path.join("/".join(self.config_data_1.data_path["DB"].split("/")[:-1]), "nid", "quickdata")
            nid_input = NidModel.load_nidmodel(nid_dir, nid_file=self.nid_file,
                                               nid_source_file_name='nid_source.txt', nid_data_file_name='nid_data.shp')
            gage_main_dam_purpose = unserialize_json(os.path.join(nid_dir, "dam_main_purpose_dict.json"))

            purpose_chosen = 'H'
            data_input1 = GagesDamDataModel(df1, nid_input, True, gage_main_dam_purpose)
            data_input1.choose_which_purpose(purpose=purpose_chosen)
            data_input2 = GagesDamDataModel(df2, nid_input, True, gage_main_dam_purpose)
            data_input2.choose_which_purpose(purpose=purpose_chosen)
            data_model = GagesInvDataModel(data_input1.gages_input, data_input2.gages_input)
            # pre_trained_model_epoch = 165
            train_lstm_inv(data_model)
            # train_lstm_inv(data_model, pre_trained_model_epoch=pre_trained_model_epoch)

    def test_data_temp_test_dam(self):
        config_data_test = self.config_data
        source_data_test = GagesSource(config_data_test, config_data_test.model_dict["data"]["tRangeTest"])
        df_test = DataModel(source_data_test)
        save_datamodel(df_test, data_source_file_name='test_data_source.txt',
                       stat_file_name='test_Statistics.json', flow_file_name='test_flow',
                       forcing_file_name='test_forcing', attr_file_name='test_attr',
                       f_dict_file_name='test_dictFactorize.json', var_dict_file_name='test_dictAttribute.json',
                       t_s_dict_file_name='test_dictTimeSpace.json')

    def test_dam_test(self):
        df_test = GagesModel.load_datamodel(self.config_data.data_path["Temp"],
                                            data_source_file_name='test_data_source.txt',
                                            stat_file_name='test_Statistics.json', flow_file_name='test_flow.npy',
                                            forcing_file_name='test_forcing.npy', attr_file_name='test_attr.npy',
                                            f_dict_file_name='test_dictFactorize.json',
                                            var_dict_file_name='test_dictAttribute.json',
                                            t_s_dict_file_name='test_dictTimeSpace.json')
        nid_input = NidModel()
        # nid_input = NidModel(self.nid_file)
        data_input_test = GagesDamDataModel(df_test, nid_input)
        pred, obs = master_test(data_input_test.gages_input)
        pred = pred.reshape(pred.shape[0], pred.shape[1])
        obs = obs.reshape(obs.shape[0], obs.shape[1])
        inds = statError(obs, pred)
        show_me_num = 5
        t_s_dict = data_input_test.gages_input.t_s_dict
        sites = np.array(t_s_dict["sites_id"])
        t_range = np.array(t_s_dict["t_final_range"])
        ts_fig = plot_ts_obs_pred(obs, pred, sites, t_range, show_me_num)
        ts_fig.savefig(os.path.join(data_input_test.gages_input.data_source.data_config.data_path["Out"], "ts_fig.png"))
        # # plot box，使用seaborn库
        keys = ["Bias", "RMSE", "NSE"]
        inds_test = subset_of_dict(inds, keys)
        box_fig = plot_boxes_inds(inds_test)
        box_fig.savefig(
            os.path.join(data_input_test.gages_input.data_source.data_config.data_path["Out"], "box_fig.png"))
        # plot map
        sites_df = pd.DataFrame({"sites": sites, keys[2]: inds_test[keys[2]]})
        plot_ind_map(data_input_test.gages_input.data_source.all_configs['gage_point_file'], sites_df)


if __name__ == '__main__':
    unittest.main()
